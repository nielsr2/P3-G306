{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 0 face(s) in this photograph.\n",
      "I found 1 face(s) in this photograph.\n",
      "The left eye in this face has the following points: [(645, 486), (661, 482), (679, 483), (697, 490), (679, 495), (660, 495)]\n",
      "The right eye in this face has the following points: [(772, 491), (791, 484), (809, 485), (827, 491), (809, 498), (791, 498)]\n",
      "I found 0 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "I found 0 face(s) in this photograph.\n",
      "I found 1 face(s) in this photograph.\n",
      "The left eye in this face has the following points: [(623, 447), (639, 440), (658, 440), (679, 449), (659, 454), (639, 455)]\n",
      "The right eye in this face has the following points: [(760, 448), (778, 439), (797, 441), (817, 447), (798, 454), (779, 454)]\n",
      "I found 1 face(s) in this photograph.\n",
      "The left eye in this face has the following points: [(627, 449), (642, 443), (660, 442), (680, 450), (661, 455), (642, 456)]\n",
      "The right eye in this face has the following points: [(760, 449), (779, 441), (797, 443), (816, 449), (798, 455), (779, 454)]\n",
      "I found 1 face(s) in this photograph.\n",
      "The left eye in this face has the following points: [(629, 451), (643, 445), (660, 445), (680, 451), (661, 456), (643, 457)]\n",
      "The right eye in this face has the following points: [(763, 452), (781, 445), (799, 447), (818, 453), (799, 458), (781, 458)]\n",
      "I found 1 face(s) in this photograph.\n",
      "The left eye in this face has the following points: [(636, 449), (651, 443), (668, 443), (686, 451), (668, 455), (651, 456)]\n",
      "The right eye in this face has the following points: [(766, 451), (785, 444), (803, 445), (820, 452), (803, 457), (784, 457)]\n",
      "I found 1 face(s) in this photograph.\n",
      "The left eye in this face has the following points: [(648, 454), (662, 450), (678, 449), (698, 453), (680, 458), (663, 459)]\n",
      "The right eye in this face has the following points: [(777, 454), (796, 450), (814, 453), (833, 458), (813, 462), (795, 461)]\n",
      "I found 1 face(s) in this photograph.\n",
      "The left eye in this face has the following points: [(643, 456), (658, 449), (675, 449), (693, 456), (676, 460), (658, 461)]\n",
      "The right eye in this face has the following points: [(774, 457), (793, 450), (810, 452), (827, 459), (809, 463), (791, 462)]\n",
      "I found 1 face(s) in this photograph.\n",
      "The left eye in this face has the following points: [(640, 459), (658, 457), (677, 456), (697, 460), (677, 466), (658, 467)]\n",
      "The right eye in this face has the following points: [(779, 461), (799, 458), (818, 460), (835, 464), (817, 469), (797, 468)]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "# This is a demo of blurring faces in video.\n",
    "\n",
    "# PLEASE NOTE: This example requires OpenCV (the `cv2` library) to be installed only to read from your webcam.\n",
    "# OpenCV is *not* required to use the face_recognition library. It's only required if you want to run this\n",
    "# specific demo. If you have trouble installing it, try any of the other demos that don't require it instead.\n",
    "\n",
    "# Get a reference to webcam #0 (the default one)\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Resize frame of video to 1/4 size for faster face detection processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # Find all the faces and face encodings in the current frame of video\n",
    "    face_locations = face_recognition.face_locations(small_frame, model=\"cnn\")\n",
    "    \n",
    "    face_landmarks_list = face_recognition.face_landmarks(frame)\n",
    "    \n",
    "    print(\"I found {} face(s) in this photograph.\".format(len(face_landmarks_list)))\n",
    "\n",
    "    # Create a PIL imagedraw object so we can draw on the picture\n",
    "    pil_image = Image.fromarray(frame)\n",
    "    d = ImageDraw.Draw(pil_image)\n",
    "\n",
    "    for face_landmarks in face_landmarks_list:\n",
    "\n",
    "        left_eye = face_landmarks['left_eye']\n",
    "        right_eye = face_landmarks['right_eye']\n",
    "        mg = (left_eye[3][0]-left_eye[0][0])*0.1\n",
    "\n",
    "        # Print the location of each facial feature in this image\n",
    "        #for left_eye in face_landmarks.keys():\n",
    "        print(\"The {} in this face has the following points: {}\".format('left eye', left_eye))\n",
    "        print(\"The {} in this face has the following points: {}\".format('right eye', right_eye))\n",
    "\n",
    "\n",
    "        if left_eye[0][1] > left_eye[3][1]:\n",
    "            d.rectangle((left_eye[0][0]-mg,left_eye[2][1]-mg,left_eye[3][0]+mg,left_eye[5][1]+mg))\n",
    "            d.rectangle((right_eye[0][0]-mg,right_eye[2][1]-mg,right_eye[3][0]+mg,right_eye[5][1]+mg))\n",
    "        else:\n",
    "            d.rectangle((left_eye[0][0]-mg,left_eye[1][1]-mg,left_eye[3][0]+mg,left_eye[4][1]+mg))\n",
    "            d.rectangle((right_eye[0][0]-mg,right_eye[1][1]-mg,right_eye[3][0]+mg,right_eye[4][1]+mg))\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
